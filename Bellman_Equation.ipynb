{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3MN0tW9eDWdV6q0L/h0Ja"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "DZjXl2QuO_G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#constants\n",
        "\n",
        "WORLD_SIZE = 5\n",
        "A_POS = [0,1]\n",
        "B_POS = [0,3]\n",
        "A_POS_PRIME = [4,1]\n",
        "B_POS_PRIME = [2,3]\n",
        "\n",
        "gamma = 0.9\n",
        "\n",
        "#left, up, right, down\n",
        "ACTIONS = [np.array([0,-1]),\n",
        "           np.array([-1,0]),\n",
        "           np.array([0,1]),\n",
        "           np.array([1,0])]\n",
        "\n",
        "ACTION_PROB = 0.25"
      ],
      "metadata": {
        "id": "FOmRHAwFPx6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step(state, action):\n",
        "  reward = None\n",
        "  next_state = None\n",
        "\n",
        "  if state == A_POS:\n",
        "    reward = 10\n",
        "    next_state = A_POS_PRIME\n",
        "  elif state ==B_POS:\n",
        "    reward = 5\n",
        "    next_state = B_POS_PRIME\n",
        "  else:\n",
        "    next_state = (np.array(state)+np.array(action)).tolist()\n",
        "    x,y = next_state\n",
        "    if(x<0 or x>=WORLD_SIZE or y<0 or y>=WORLD_SIZE):\n",
        "      reward = -1.0\n",
        "      next_state = state\n",
        "    else:\n",
        "      reward = 0.0\n",
        "      next_state = (np.array(state) + np.array(action)).tolist()\n",
        "\n",
        "  return next_state, reward"
      ],
      "metadata": {
        "id": "yDQoSNdLRGH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bellman_update(value):\n",
        "  new_value = np.zeros_like(value)\n",
        "\n",
        "  for i in range (WORLD_SIZE) :\n",
        "    for j in range (WORLD_SIZE) :\n",
        "      value_sum = 0\n",
        "      for action in ACTIONS:\n",
        "        #getting next state and reward\n",
        "        (next_i, next_j), reward = step([i,j], action)\n",
        "\n",
        "        value_sum += ACTION_PROB * (reward + gamma * value[next_i, next_j])\n",
        "\n",
        "      new_value[i][j] = value_sum\n",
        "  return new_value"
      ],
      "metadata": {
        "id": "1Z3NyTwOUvnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_0 = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
        "VALUE = np.zeros((10001, WORLD_SIZE, WORLD_SIZE), dtype=float)\n",
        "VALUE[0] = value_0\n",
        "for i in range(10000):\n",
        "  VALUE[i+1] = bellman_update(VALUE[i])\n",
        "\n",
        "print(VALUE[-1])\n",
        "\n",
        "#Hence we can say that the values presented in book is correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl8hGNgNWUSq",
        "outputId": "094e97b6-4cd4-44d3-a5af-c6d118dbd38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.30899634  8.78929186  4.42761918  5.32236759  1.49217876]\n",
            " [ 1.52158807  2.99231786  2.25013995  1.9075717   0.54740271]\n",
            " [ 0.05082249  0.73817059  0.67311326  0.35818621 -0.40314114]\n",
            " [-0.9735923  -0.43549543 -0.35488227 -0.58560509 -1.18307508]\n",
            " [-1.85770055 -1.34523126 -1.22926726 -1.42291815 -1.97517905]]\n"
          ]
        }
      ]
    }
  ]
}